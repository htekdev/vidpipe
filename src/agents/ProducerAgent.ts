import type { ToolWithHandler } from '../providers/types.js'
import { BaseAgent } from './BaseAgent.js'
import type { VideoInfo } from '../tools/agentTools.js'
import { singlePassEdit, type KeepSegment } from '../tools/ffmpeg/singlePassEdit.js'
import type { VideoAsset } from '../assets/VideoAsset.js'
import logger from '../config/logger.js'

// ── System prompt ───────────────────────────────────────────────────────────

const SYSTEM_PROMPT = `You are a professional video cleaner. Your job is to analyze videos and identify regions that should be removed for a tighter, cleaner edit.

## CONTEXT TOOLS (use these first to understand the video)
- **get_video_info**: Get video dimensions, duration, and frame rate
- **get_transcript**: Read what's being said (with optional time range filtering)
- **get_editorial_direction**: Get AI-generated editorial guidance (cut points, pacing notes) from Gemini video analysis. Use this to inform your cleaning decisions.

## WHAT TO REMOVE
- **Dead air**: Long silences with no meaningful content
- **Filler words**: Excessive "um", "uh", "like", "you know" clusters
- **Bad takes**: False starts, stumbles, repeated sentences where the speaker restarts
- **Long pauses**: Extended gaps between sentences (>3 seconds) that don't serve a purpose
- **Redundant content**: Sections where the same point is repeated without adding value

## WHAT TO PRESERVE
- **Intentional pauses**: Dramatic pauses, thinking pauses before important points
- **Demonstrations**: Silence during live coding, UI interaction, or waiting for results
- **Meaningful silence**: Pauses that give the viewer time to absorb information
- **All substantive content**: When in doubt, keep it

## WORKFLOW

1. Call get_video_info to know the video duration
2. Call get_editorial_direction to get AI-powered editorial guidance (cut points, pacing issues)
3. Call get_transcript (in sections if long) to understand what's being said and find removable regions
4. When ready, call **plan_cuts** with your list of regions to remove

## GUIDELINES
- **Follow the editorial direction closely** — it was generated by Gemini video AI analysis. If it says to cut a region, cut it. If it says to remove an entire segment, remove it.
- Pay special attention to **Pacing Analysis** and **Cleaning Recommendations** sections — these are mandatory cut instructions, not suggestions.
- If the editorial direction recommends starting the video at a specific timestamp (e.g. "start at 00:15"), remove everything before that point.
- Each removal should have a clear reason
- Don't remove short pauses (<1 second) unless the editorial direction specifically flags them
- Focus on making the video tighter and following the editorial vision`

// ── Types ────────────────────────────────────────────────────────────────────

interface Removal {
  start: number
  end: number
  reason: string
}

interface MandatoryCut {
  start: number
  end: number
  reason: string
  confidence: string
}

interface GetTranscriptArgs {
  start?: number
  end?: number
}

// ── Helpers ──────────────────────────────────────────────────────────────────

/**
 * Parse mandatory cuts from editorial direction.
 * Looks for the ```json:cuts block first (structured output from Gemini),
 * falls back to regex parsing of markdown timestamps.
 * Merges overlapping/adjacent cuts (within 2s gap) to avoid fragmented removals.
 */
function parseMandatoryCuts(direction: string): MandatoryCut[] {
  let cuts: MandatoryCut[] = []

  // Try structured JSON block first
  const jsonMatch = direction.match(/```json:cuts\s*\n([\s\S]*?)```/)
  if (jsonMatch) {
    try {
      const parsed = JSON.parse(jsonMatch[1]) as MandatoryCut[]
      cuts = parsed.filter(c => c.end > c.start)
    } catch {
      logger.warn('[ProducerAgent] Failed to parse json:cuts block, falling back to regex')
    }
  }

  // Fallback: parse markdown timestamps from Cleaning Recommendations
  if (cuts.length === 0) {
    const sectionMatch = direction.match(/#{2,3}\s*Cleaning Recommendations\s*\n([\s\S]*?)(?=\n#{2,3}\s|\n---|\n$|$)/)
    if (!sectionMatch) return cuts

    const section = sectionMatch[1]
    const linePattern = /\*\*(\d{2}):(\d{2})\s*-\s*(\d{2}):(\d{2}):\*\*/g
    let match
    while ((match = linePattern.exec(section)) !== null) {
      const start = parseInt(match[1]) * 60 + parseInt(match[2])
      const end = parseInt(match[3]) * 60 + parseInt(match[4])
      if (end > start) {
        cuts.push({ start, end, reason: 'Flagged by editorial direction', confidence: 'High' })
      }
    }
  }

  return mergeMandatoryCuts(cuts)
}

/** Merge overlapping or adjacent cuts (gap <= 2 seconds) into larger ranges. */
function mergeMandatoryCuts(cuts: MandatoryCut[]): MandatoryCut[] {
  if (cuts.length <= 1) return cuts

  const sorted = [...cuts].sort((a, b) => a.start - b.start)
  const merged: MandatoryCut[] = [sorted[0]]

  for (let i = 1; i < sorted.length; i++) {
    const prev = merged[merged.length - 1]
    const curr = sorted[i]
    if (curr.start <= prev.end + 2) {
      // Merge: extend the previous cut
      prev.end = Math.max(prev.end, curr.end)
      prev.reason = `${prev.reason}; ${curr.reason}`
    } else {
      merged.push({ ...curr })
    }
  }

  return merged
}

// ── JSON Schemas ─────────────────────────────────────────────────────────────

const PLAN_CUTS_SCHEMA = {
  type: 'object',
  properties: {
    removals: {
      type: 'array',
      description: 'Array of regions to remove from the video',
      items: {
        type: 'object',
        properties: {
          start: { type: 'number', description: 'Start time in seconds' },
          end: { type: 'number', description: 'End time in seconds' },
          reason: { type: 'string', description: 'Why this region should be removed' },
        },
        required: ['start', 'end', 'reason'],
      },
    },
  },
  required: ['removals'],
}

/**
 * Result of the produce() method.
 */
export interface ProduceResult {
  /** The agent's summary of edits made */
  summary: string
  /** Path to the output video (if rendering succeeded) */
  outputPath?: string
  /** Whether FFmpeg rendering succeeded */
  success: boolean
  /** Error message if rendering failed */
  error?: string
  /** Number of edits planned */
  editCount?: number
  /** Regions removed from the video */
  removals: { start: number; end: number }[]
  /** Segments kept in the output video */
  keepSegments: { start: number; end: number }[]
}

// ── ProducerAgent ────────────────────────────────────────────────────────────

export class ProducerAgent extends BaseAgent {
  private readonly video: VideoAsset
  private videoDuration: number = 0
  private removals: Removal[] = []

  constructor(video: VideoAsset, model?: string) {
    super('ProducerAgent', SYSTEM_PROMPT, undefined, model)
    this.video = video
  }

  protected getTools(): ToolWithHandler[] {
    return [
      {
        name: 'get_video_info',
        description: 'Get video metadata: dimensions, duration, and frame rate.',
        parameters: { type: 'object', properties: {} },
        handler: async () => this.handleToolCall('get_video_info', {}),
      },
      {
        name: 'get_transcript',
        description: 'Read the transcript with optional time range filtering.',
        parameters: {
          type: 'object',
          properties: {
            start: { type: 'number', description: 'Optional start time in seconds' },
            end: { type: 'number', description: 'Optional end time in seconds' },
          },
        },
        handler: async (rawArgs: unknown) =>
          this.handleToolCall('get_transcript', rawArgs as Record<string, unknown>),
      },
      {
        name: 'get_editorial_direction',
        description:
          'Get AI-generated editorial guidance from Gemini video analysis. ' +
          'Returns timestamped cut points, pacing notes, and recommendations for cleaning.',
        parameters: { type: 'object', properties: {} },
        handler: async () => this.handleToolCall('get_editorial_direction', {}),
      },
      {
        name: 'plan_cuts',
        description:
          'Submit your list of regions to remove from the video. Call this ONCE with ALL planned removals.',
        parameters: PLAN_CUTS_SCHEMA,
        handler: async (rawArgs: unknown) =>
          this.handleToolCall('plan_cuts', rawArgs as Record<string, unknown>),
      },
    ]
  }

  protected async handleToolCall(
    toolName: string,
    args: Record<string, unknown>,
  ): Promise<unknown> {
    switch (toolName) {
      case 'get_video_info': {
        logger.info(`[ProducerAgent] Getting video info`)
        const metadata = await this.video.getMetadata()
        this.videoDuration = metadata.duration
        return {
          width: metadata.width,
          height: metadata.height,
          duration: metadata.duration,
          fps: 30,
        } as VideoInfo
      }

      case 'get_transcript': {
        const { start, end } = args as GetTranscriptArgs
        logger.info(`[ProducerAgent] Reading transcript${start !== undefined ? ` (${start}s-${end}s)` : ''}`)

        const transcript = await this.video.getTranscript()

        let segments = transcript.segments
        if (start !== undefined || end !== undefined) {
          segments = segments.filter(s => {
            if (start !== undefined && s.end < start) return false
            if (end !== undefined && s.start > end) return false
            return true
          })
        }

        return {
          text: segments.map(s => s.text).join(' '),
          segments: segments.map(s => ({
            text: s.text,
            start: s.start,
            end: s.end,
          })),
        }
      }

      case 'get_editorial_direction': {
        logger.info(`[ProducerAgent] Getting editorial direction from Gemini`)

        const direction = await this.video.getEditorialDirection()

        if (!direction) {
          return {
            available: false,
            message: 'Editorial direction not available (GEMINI_API_KEY not configured). Plan cuts based on transcript analysis.',
          }
        }

        // Parse mandatory cuts from Cleaning Recommendations section
        const mandatoryCuts = parseMandatoryCuts(direction)

        return {
          available: true,
          editorialDirection: direction,
          mandatoryCuts,
          instructions: mandatoryCuts.length > 0
            ? `MANDATORY: The following ${mandatoryCuts.length} cuts were identified by Gemini video AI. You MUST include ALL of them in your plan_cuts call. You may add additional cuts you find, but these are non-negotiable.`
            : 'No mandatory cuts identified. Use your judgment based on the editorial direction.',
        }
      }

      case 'plan_cuts': {
        const { removals } = args as { removals: Removal[] }
        logger.info(`[ProducerAgent] Received plan with ${removals.length} removals`)
        this.removals = removals
        return `Plan received with ${removals.length} removals. Video will be rendered automatically.`
      }

      default:
        throw new Error(`Unknown tool: ${toolName}`)
    }
  }

  /**
   * Run the producer agent to clean the video by removing unwanted segments.
   *
   * @param outputPath - Path for the output video
   */
  async produce(outputPath: string): Promise<ProduceResult> {
    this.removals = []

    const prompt = `Analyze this video and decide which segments should be removed for a cleaner edit.

**Video:** ${this.video.videoPath}

## Instructions

1. Call get_video_info to know the video duration.
2. Call get_editorial_direction to get AI-powered editorial guidance (cut points, pacing issues).
3. Call get_transcript to understand what's being said and identify removable regions.
4. Call **plan_cuts** with your list of regions to remove.

Focus on removing dead air, filler words, bad takes, and redundant content. Follow the editorial direction closely — if it identifies cut points, apply them. The editorial direction has been carefully analyzed by Gemini video AI, so trust its recommendations.`

    try {
      const response = await this.run(prompt)
      logger.info(`[ProducerAgent] Agent planning complete for ${this.video.videoPath}`)

      if (this.removals.length === 0) {
        logger.info(`[ProducerAgent] No removals planned — video is clean`)
        return {
          summary: response,
          success: true,
          editCount: 0,
          removals: [],
          keepSegments: [{ start: 0, end: this.videoDuration }],
        }
      }

      // Sort by start time for keepSegment construction
      const totalRemoval = this.removals.reduce((sum, r) => sum + (r.end - r.start), 0)
      const sortedRemovals = [...this.removals].sort((a, b) => a.start - b.start)

      // Convert removals to keepSegments (inverse)
      const keepSegments: KeepSegment[] = []
      let cursor = 0
      for (const removal of sortedRemovals) {
        if (removal.start > cursor) {
          keepSegments.push({ start: cursor, end: removal.start })
        }
        cursor = Math.max(cursor, removal.end)
      }
      if (cursor < this.videoDuration) {
        keepSegments.push({ start: cursor, end: this.videoDuration })
      }

      logger.info(
        `[ProducerAgent] ${this.removals.length} removals → ${keepSegments.length} keep segments, removing ${totalRemoval.toFixed(1)}s`,
      )

      // Render via singlePassEdit
      await singlePassEdit(this.video.videoPath, keepSegments, outputPath)

      logger.info(`[ProducerAgent] Render complete: ${outputPath}`)

      return {
        summary: response,
        outputPath,
        success: true,
        editCount: this.removals.length,
        removals: sortedRemovals.map(r => ({ start: r.start, end: r.end })),
        keepSegments,
      }
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err)
      logger.error(`[ProducerAgent] Production failed: ${message}`)
      return {
        summary: `Production failed: ${message}`,
        success: false,
        error: message,
        removals: [],
        keepSegments: [],
      }
    } finally {
      await this.destroy()
    }
  }
}
