<div align="center">

```
 â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
 â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•
 â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  
 â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•”â•â•â•  
  â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
   â•šâ•â•â•â•  â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•     â•šâ•â•â•šâ•â•     â•šâ•â•â•â•â•â•â•
```

**Drop a video. Get transcripts, summaries, short clips, captions, blog posts, and social media posts â€” automatically.**

An AI-powered CLI pipeline that watches for new video recordings and transforms them into rich, structured content using [GitHub Copilot SDK](https://github.com/github/copilot-sdk) agents and OpenAI Whisper.

[![CI](https://github.com/htekdev/vidpipe/actions/workflows/ci.yml/badge.svg)](https://github.com/htekdev/vidpipe/actions/workflows/ci.yml)
[![npm version](https://img.shields.io/npm/v/vidpipe)](https://www.npmjs.com/package/vidpipe)
[![Node.js 20+](https://img.shields.io/badge/node-20%2B-brightgreen)](https://nodejs.org/)
[![License: ISC](https://img.shields.io/badge/license-ISC-blue)](./LICENSE)

</div>

```bash
npm install -g vidpipe
```

---

## âœ¨ Features

<div align="center">
  <img src="assets/features-infographic.png" alt="VidPipe Features â€” Input â†’ AI Processing â†’ Outputs" width="900" />
</div>

<br />

<table>
  <tr>
    <td>ğŸ™ï¸ <b>Whisper Transcription</b> â€” Word-level timestamps</td>
    <td>ğŸ“ <b>Split-Screen Layouts</b> â€” Portrait, square, and feed</td>
  </tr>
  <tr>
    <td>ğŸ”‡ <b>AI Silence Removal</b> â€” Context-aware, capped at 20%</td>
    <td>ğŸ’¬ <b>Karaoke Captions</b> â€” Word-by-word highlighting</td>
  </tr>
  <tr>
    <td>âœ‚ï¸ <b>Short Clips</b> â€” Best 15â€“60s moments, multi-segment</td>
    <td>ğŸï¸ <b>Medium Clips</b> â€” 1â€“3 min with crossfade transitions</td>
  </tr>
  <tr>
    <td>ğŸ“‘ <b>Chapter Detection</b> â€” JSON, Markdown, YouTube, FFmeta</td>
    <td>ğŸ“± <b>Social Posts</b> â€” TikTok, YouTube, Instagram, LinkedIn, X</td>
  </tr>
  <tr>
    <td>ğŸ“° <b>Blog Post</b> â€” Dev.to style with web-sourced links</td>
    <td>ğŸ¨ <b>Brand Voice</b> â€” Custom tone, hashtags via brand.json</td>
  </tr>
  <tr>
    <td>ğŸ” <b>Face Detection</b> â€” ONNX-based webcam cropping</td>
    <td>ğŸ”„ <b>Git Automation</b> â€” Auto-commit and push after each video</td>
  </tr>
</table>

---

## ğŸš€ Quick Start

```bash
# Install globally
npm install -g vidpipe

# Set up your environment
# Unix/Mac
cp .env.example .env
# Windows (PowerShell)
Copy-Item .env.example .env

# Then edit .env and add your OpenAI API key (REQUIRED):
#   OPENAI_API_KEY=sk-your-key-here

# Verify all prerequisites are met
vidpipe --doctor

# Process a single video
vidpipe /path/to/video.mp4

# Watch a folder for new recordings
vidpipe --watch-dir ~/Videos/Recordings

# Full example with options
vidpipe \
  --watch-dir ~/Videos/Recordings \
  --output-dir ~/Content/processed \
  --openai-key sk-... \
  --brand ./brand.json \
  --verbose
```

> **Prerequisites:**
> - **Node.js 20+**
> - **FFmpeg 6.0+** â€” Auto-bundled on common platforms (Windows x64, macOS, Linux x64) via [`ffmpeg-static`](https://www.npmjs.com/package/ffmpeg-static). On other architectures, install system FFmpeg (see [Troubleshooting](#troubleshooting)). Override with `FFMPEG_PATH` env var if you need a specific build.
> - **OpenAI API key** (**required**) â€” Get one at [platform.openai.com/api-keys](https://platform.openai.com/api-keys). Needed for Whisper transcription and all AI features.
> - **GitHub Copilot subscription** â€” Required for AI agent features (shorts generation, social media posts, summaries, blog posts). See [GitHub Copilot](https://github.com/features/copilot).
>
> See [Getting Started](./docs/getting-started.md) for full setup instructions.

---

## ğŸ® CLI Usage

```
vidpipe [options] [video-path]
vidpipe init              # Interactive setup wizard
vidpipe review            # Open post review web app
vidpipe schedule          # View posting schedule
```

| Option | Description |
|--------|-------------|
| `--doctor` | Check that all prerequisites (FFmpeg, API keys, etc.) are installed and configured |
| `[video-path]` | Process a specific video file (implies `--once`) |
| `--watch-dir <path>` | Folder to watch for new recordings |
| `--output-dir <path>` | Output directory (default: `./recordings`) |
| `--openai-key <key>` | OpenAI API key |
| `--exa-key <key>` | Exa AI key for web search in social posts |
| `--brand <path>` | Path to `brand.json` (default: `./brand.json`) |
| `--once` | Process next video and exit |
| `--no-silence-removal` | Skip silence removal |
| `--no-shorts` | Skip short clip extraction |
| `--no-medium-clips` | Skip medium clip generation |
| `--no-social` | Skip social media posts |
| `--no-social-publish` | Skip social media queue-build stage |
| `--late-api-key <key>` | Override Late API key |
| `--no-captions` | Skip caption generation/burning |
| `--no-git` | Skip git commit/push |
| `-v, --verbose` | Debug-level logging |

---

## ğŸ“ Output Structure

```
recordings/
â””â”€â”€ my-awesome-demo/
    â”œâ”€â”€ my-awesome-demo.mp4                  # Original video
    â”œâ”€â”€ my-awesome-demo-edited.mp4           # Silence-removed
    â”œâ”€â”€ my-awesome-demo-captioned.mp4        # With burned-in captions
    â”œâ”€â”€ transcript.json                      # Word-level transcript
    â”œâ”€â”€ transcript-edited.json               # Timestamps adjusted for silence removal
    â”œâ”€â”€ README.md                            # AI-generated summary with screenshots
    â”œâ”€â”€ captions/
    â”‚   â”œâ”€â”€ captions.srt                     # SubRip subtitles
    â”‚   â”œâ”€â”€ captions.vtt                     # WebVTT subtitles
    â”‚   â””â”€â”€ captions.ass                     # Advanced SSA (karaoke-style)
    â”œâ”€â”€ shorts/
    â”‚   â”œâ”€â”€ catchy-title.mp4                 # Landscape base clip
    â”‚   â”œâ”€â”€ catchy-title-captioned.mp4       # Landscape + burned captions
    â”‚   â”œâ”€â”€ catchy-title-portrait.mp4        # 9:16 split-screen
    â”‚   â”œâ”€â”€ catchy-title-portrait-captioned.mp4  # Portrait + captions + hook overlay
    â”‚   â”œâ”€â”€ catchy-title-feed.mp4            # 4:5 split-screen
    â”‚   â”œâ”€â”€ catchy-title-square.mp4          # 1:1 split-screen
    â”‚   â”œâ”€â”€ catchy-title.md                  # Clip metadata
    â”‚   â””â”€â”€ catchy-title/
    â”‚       â””â”€â”€ posts/                       # Per-short social posts (5 platforms)
    â”œâ”€â”€ medium-clips/
    â”‚   â”œâ”€â”€ deep-dive-topic.mp4              # Landscape base clip
    â”‚   â”œâ”€â”€ deep-dive-topic-captioned.mp4    # With burned captions
    â”‚   â”œâ”€â”€ deep-dive-topic.md               # Clip metadata
    â”‚   â””â”€â”€ deep-dive-topic/
    â”‚       â””â”€â”€ posts/                       # Per-clip social posts (5 platforms)
    â”œâ”€â”€ chapters/
    â”‚   â”œâ”€â”€ chapters.json                    # Structured chapter data
    â”‚   â”œâ”€â”€ chapters.md                      # Markdown table
    â”‚   â”œâ”€â”€ chapters.ffmetadata              # FFmpeg metadata format
    â”‚   â””â”€â”€ chapters-youtube.txt             # YouTube description timestamps
    â””â”€â”€ social-posts/
        â”œâ”€â”€ tiktok.md                        # Full-video social posts
        â”œâ”€â”€ youtube.md
        â”œâ”€â”€ instagram.md
        â”œâ”€â”€ linkedin.md
        â”œâ”€â”€ x.md
        â””â”€â”€ devto.md                         # Dev.to blog post
```

---

## ğŸ“º Review App

VidPipe includes a built-in web app for reviewing, editing, and scheduling social media posts before publishing.

<div align="center">
  <img src="assets/review-ui.png" alt="VidPipe Review UI" width="800" />
  <br />
  <em>Review and approve posts across YouTube, TikTok, Instagram, LinkedIn, and X/Twitter</em>
</div>

```bash
# Launch the review app
vidpipe review
```

- **Platform tabs** â€” Filter posts by platform (YouTube, TikTok, Instagram, LinkedIn, X)
- **Video preview** â€” See the video thumbnail and content before approving
- **Keyboard shortcuts** â€” Arrow keys to navigate, Enter to approve, Backspace to reject
- **Smart scheduling** â€” Posts are queued with optimal timing per platform

---

## ğŸ”„ Pipeline

```mermaid
graph LR
    A[ğŸ“¥ Ingest] --> B[ğŸ™ï¸ Transcribe]
    B --> C[ğŸ”‡ Silence Removal]
    C --> D[ğŸ’¬ Captions]
    D --> E[ğŸ”¥ Caption Burn]
    E --> F[âœ‚ï¸ Shorts]
    F --> G[ğŸï¸ Medium Clips]
    G --> H[ğŸ“‘ Chapters]
    H --> I[ğŸ“ Summary]
    I --> J[ğŸ“± Social Media]
    J --> K[ğŸ“± Short Posts]
    K --> L[ğŸ“± Medium Posts]
    L --> M[ğŸ“° Blog]
    M --> N[ğŸ”„ Git Push]

    style A fill:#2d5a27,stroke:#4ade80
    style B fill:#1e3a5f,stroke:#60a5fa
    style E fill:#5a2d27,stroke:#f87171
    style F fill:#5a4d27,stroke:#fbbf24
    style N fill:#2d5a27,stroke:#4ade80
```

| # | Stage | Description |
|---|-------|-------------|
| 1 | **Ingestion** | Copies video, extracts metadata with FFprobe |
| 2 | **Transcription** | Extracts audio â†’ OpenAI Whisper for word-level transcription |
| 3 | **Silence Removal** | AI detects dead-air segments; context-aware removals capped at 20% |
| 4 | **Captions** | Generates `.srt`, `.vtt`, and `.ass` subtitle files with karaoke word highlighting |
| 5 | **Caption Burn** | Burns ASS captions into video (single-pass encode when silence was also removed) |
| 6 | **Shorts** | AI identifies best 15â€“60s moments; extracts single and composite clips with 6 variants per short |
| 7 | **Medium Clips** | AI identifies 1â€“3 min standalone segments with crossfade transitions |
| 8 | **Chapters** | AI detects topic boundaries; outputs JSON, Markdown, FFmetadata, and YouTube timestamps |
| 9 | **Summary** | AI writes a Markdown README with captured screenshots |
| 10 | **Social Media** | Platform-tailored posts for TikTok, YouTube, Instagram, LinkedIn, and X |
| 11 | **Short Posts** | Per-short social media posts for all 5 platforms |
| 12 | **Medium Clip Posts** | Per-medium-clip social media posts for all 5 platforms |
| 13 | **Blog** | Dev.to blog post with frontmatter, web-sourced links via Exa |
| 14 | **Git Push** | Auto-commits and pushes to `origin main` |

Each stage can be independently skipped with `--no-*` flags. A stage failure does not abort the pipeline â€” subsequent stages proceed with whatever data is available.

---

## ğŸ¤– LLM Providers

VidPipe supports multiple LLM providers:

| Provider | Env Var | Default Model | Notes |
|----------|---------|---------------|-------|
| `copilot` (default) | â€” | Claude Opus 4.6 | Uses GitHub Copilot auth |
| `openai` | `OPENAI_API_KEY` | gpt-4o | Direct OpenAI API |
| `claude` | `ANTHROPIC_API_KEY` | claude-opus-4.6 | Direct Anthropic API |

Set `LLM_PROVIDER` in your `.env` or pass via CLI. Override model with `LLM_MODEL`.

The pipeline tracks token usage and estimated cost across all providers, displaying a summary at the end of each run.

---

## âš™ï¸ Configuration

Configuration is loaded from CLI flags â†’ environment variables â†’ `.env` file â†’ defaults.

```env
# .env
OPENAI_API_KEY=sk-your-key-here
WATCH_FOLDER=/path/to/recordings
OUTPUT_DIR=/path/to/output
# EXA_API_KEY=your-exa-key       # Optional: enables web search in social/blog posts
# BRAND_PATH=./brand.json         # Optional: path to brand voice config
# FFMPEG_PATH=/usr/local/bin/ffmpeg
# FFPROBE_PATH=/usr/local/bin/ffprobe
# LATE_API_KEY=sk_your_key_here   # Optional: Late API for social publishing
```

Social media publishing is configured via `schedule.json` and the Late API. See [Social Publishing Guide](./docs/social-publishing.md) for details.

---

## ğŸ“š Documentation

| Guide | Description |
|-------|-------------|
| [Getting Started](./docs/getting-started.md) | Prerequisites, installation, and first run |
| [Configuration](./docs/configuration.md) | All CLI flags, env vars, skip options, and examples |
| [FFmpeg Setup](./docs/ffmpeg-setup.md) | Platform-specific install (Windows, macOS, Linux, ARM64) |
| [Brand Customization](./docs/brand-customization.md) | Customize AI voice, vocabulary, hashtags, and content style |
| [Social Publishing](./docs/social-publishing.md) | Review, schedule, and publish social posts via Late API |

---

## ğŸ—ï¸ Architecture

Agent-based architecture built on the [GitHub Copilot SDK](https://github.com/github/copilot-sdk):

```mermaid
graph TD
    BP[ğŸ§  BaseAgent] --> SRA[SilenceRemovalAgent]
    BP --> SA[SummaryAgent]
    BP --> SHA[ShortsAgent]
    BP --> MVA[MediumVideoAgent]
    BP --> CA[ChapterAgent]
    BP --> SMA[SocialMediaAgent]
    BP --> BA[BlogAgent]

    SRA -->|tools| T1[detect_silence, decide_removals]
    SHA -->|tools| T2[plan_shorts]
    MVA -->|tools| T3[plan_medium_clips]
    CA -->|tools| T4[generate_chapters]
    SA -->|tools| T5[capture_frame, write_summary]
    SMA -->|tools| T6[search_links, create_posts]
    BA -->|tools| T7[search_web, write_blog]

    style BP fill:#1e3a5f,stroke:#60a5fa,color:#fff
```

Each agent communicates with the LLM through structured tool calls, ensuring reliable, parseable outputs.

---

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| [TypeScript](https://www.typescriptlang.org/) | Language (ES2022, ESM) |
| [GitHub Copilot SDK](https://github.com/github/copilot-sdk) | AI agent framework |
| [OpenAI Whisper](https://platform.openai.com/docs/guides/speech-to-text) | Speech-to-text |
| [FFmpeg](https://ffmpeg.org/) | Video/audio processing |
| [Sharp](https://sharp.pixelplumbing.com/) | Image analysis (webcam detection) |
| [Commander.js](https://github.com/tj/commander.js) | CLI framework |
| [Chokidar](https://github.com/paulmillr/chokidar) | File system watching |
| [Winston](https://github.com/winstonjs/winston) | Logging |
| [Exa AI](https://exa.ai/) | Web search for social posts and blog |

---

## ğŸ—ºï¸ Roadmap

- [x] **Automated social posting** â€” Publish directly to platforms via Late API
- [ ] **Multi-language support** â€” Transcription and summaries in multiple languages
- [ ] **Custom templates** â€” User-defined Markdown & social post templates
- [ ] **Web dashboard** â€” Browser UI for reviewing and editing outputs
- [ ] **Batch processing** â€” Process an entire folder of existing videos
- [ ] **Custom short criteria** â€” Configure what makes a "good" short for your content
- [ ] **Thumbnail generation** â€” Auto-generate branded thumbnails for shorts

---

## ğŸ”§ Troubleshooting

### `No binary found for architecture` during install

`ffmpeg-static` (an optional dependency) bundles FFmpeg for common platforms. On unsupported architectures, it skips gracefully and vidpipe falls back to your system FFmpeg.

**Fix:** Install FFmpeg on your system:
- **Windows:** `winget install Gyan.FFmpeg`
- **macOS:** `brew install ffmpeg`
- **Linux:** `sudo apt install ffmpeg` (Debian/Ubuntu) or `sudo dnf install ffmpeg` (Fedora)

You can also point to a custom binary: `export FFMPEG_PATH=/path/to/ffmpeg`

Run `vidpipe doctor` to verify your setup.

---

## ğŸ“„ License

ISC Â© [htekdev](https://github.com/htekdev)
